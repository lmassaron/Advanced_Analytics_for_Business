# config file for pipeline_script.py
ENDPOINT_NAME : 'klrealestate'
# from https://cloud.google.com/vertex-ai/docs/training/pre-built-containers
train_image : "us-docker.pkg.dev/vertex-ai/training/tf-cpu.2-9:latest"
# from https://cloud.google.com/vertex-ai/docs/predictions/pre-built-containers
deploy_image : "us-docker.pkg.dev/vertex-ai/prediction/tf2-cpu.2-9:latest"
config_file_path : "model_training_config.yml"
# Google Cloud Storage file containing the config settings for the training script

script_path : "model_training_keras_preprocessing.py"
# hardware spec for training and deployment
machine_type : 'n1-standard-4'
machine_type_deploy : 'n1-standard-2'
# project details
project_id : 'first-project-ml-tabular'
region : 'us-central1'
dataset_id : '3777312823596548096'
# Google Cloud Storage URIs
staging_path : "gs://first-project-ml-tabular-bucket/staging/"
config_bucket_path : "gs://first-project-ml-tabular-bucket/model_training_config.yml"
# training specs - these supercede the splits in the model training config
training_fraction_split : 0.8
validation_fraction_split : 0.1
test_fraction_split : 0.1
# switch to control whether trained model is deployed to a Vertex AI endpoint
deploy_model: TRUE